{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_predictions = np.loadtxt(\"naive_bayes_predictions.txt\") \n",
    "lightGBM_predictions = np.loadtxt(\"lightGBM_predictions.txt\") \n",
    "y_test = pd.read_csv(\"y_test.csv\", header=None, names = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Blending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models blending: LightGBM + Gaussian Naive Bayes \n",
    "# Calculating the weights\n",
    "\n",
    "auc = {}\n",
    "for weight in [x/100 for x in range(0,101)]:\n",
    "    combined_preds = []\n",
    "    for i in range(y_test.shape[0]):\n",
    "        combined_pred = naive_bayes_predictions[i] * weight + lightGBM_predictions[i] * (1-weight)\n",
    "        combined_preds.append(combined_pred)\n",
    "    auc[weight] = roc_auc_score(y_test['target'], combined_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weight = max(auc, key=auc.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combined_pred = naive_bayes_predictions*optimal_weight + lightGBM_predictions*(1-optimal_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.90084 \n"
     ]
    }
   ],
   "source": [
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(y_test['target'], final_combined_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('blending_result.txt', final_combined_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Stacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (100000, 400)\n",
      "y_train shape:  (100000, 1)\n",
      "x_test shape:  (100000, 400)\n",
      "y_test shape:  (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Use the data with Frequency Count FE.\n",
    "\n",
    "x_train = pd.read_csv(\"x_train_FE.csv\")\n",
    "y_train = pd.read_csv(\"y_train_FE.csv\")\n",
    "x_test = pd.read_csv(\"x_test_FE.csv\")\n",
    "y_test = pd.read_csv(\"y_test_FE.csv\")\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(scaled_df)\n",
    "scaled_df = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "0.8796017858649708\n",
      "Fold:  2\n",
      "0.8821009840981637\n",
      "Fold:  3\n",
      "0.8740916499870713\n",
      "Fold:  4\n",
      "0.8774067419095065\n",
      "Fold:  5\n",
      "0.8767693248527761\n",
      "Fold:  6\n",
      "0.8732832182569688\n"
     ]
    }
   ],
   "source": [
    "# Set up level 1 models\n",
    "RANDOM_SEED = 16\n",
    "lgbm = LGBMClassifier(application='binary',\n",
    "                      boosting='gbdt',\n",
    "                      learning_rate= 0.01,\n",
    "                      num_leaves=73,\n",
    "                      tree_learner='serial',\n",
    "                      num_threads=0,                      \n",
    "                      max_depth=23,\n",
    "                      min_data_in_leaf=5,\n",
    "                      min_sum_hessian_in_leaf=35.74237455449936,\n",
    "                      bagging_fraction=0.9476322568516703,\n",
    "                      bagging_freq=0,\n",
    "                      feature_fraction=1.0,\n",
    "                      lambda_l1=2.9721007219556626,\n",
    "                      lambda_l2=2.1415434246484737,\n",
    "                      boost_from_average=True,                      \n",
    "                      metric='auc'\n",
    "                     )\n",
    "nb = GaussianNB()\n",
    "\n",
    "# set up the meta classifier (level 2 model)\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "sclf = StackingCVClassifier(classifiers=[nb, lgbm], \n",
    "                            use_probas=True,\n",
    "                            use_features_in_secondary=True,\n",
    "                            meta_classifier=lr,\n",
    "                            cv=6)\n",
    "\n",
    "# Set up K-Fold cross validation and predictions\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 6\n",
    "folds = KFold(n_splits=num_folds, random_state=16)\n",
    "test_result = np.zeros(len(y_test))\n",
    "auc_score = 0\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(\"Fold: \", fold_ + 1)\n",
    "    \n",
    "    X_train, Y_train = x_train.iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    X_valid, Y_valid = x_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    sclf.fit(X_train.values, Y_train['0'].values)\n",
    "    \n",
    "    Y_pred = sclf.predict_proba(X_valid)\n",
    "    auc = roc_auc_score(Y_valid, Y_pred[:, 1])\n",
    "    print(auc)\n",
    "    auc_score += auc\n",
    "\n",
    "    preds = sclf.predict_proba(x_test)\n",
    "    test_result += preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.8772089508282429\n"
     ]
    }
   ],
   "source": [
    "# print the average AUC across the folds and compute the final results on the test data\n",
    "auc_score = auc_score / folds.n_splits\n",
    "print(\"AUC score: \", auc_score)\n",
    "test_result = test_result / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.53393 \n"
     ]
    }
   ],
   "source": [
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(y_test, test_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data without feature engineering FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (100000, 200)\n",
      "y_train shape:  (100000, 1)\n",
      "x_test shape:  (100000, 200)\n",
      "y_test shape:  (100000, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"whole_data.csv\")\n",
    "\n",
    "x_train = pd.read_csv(\"x_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names = ['target'])\n",
    "x_test = pd.read_csv(\"x_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\", header=None, names = ['target'])\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(scaled_df)\n",
    "scaled_df = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "0.8846742376077751\n",
      "Fold:  2\n",
      "0.8849005074548123\n",
      "Fold:  3\n",
      "0.8781716354303336\n",
      "Fold:  4\n",
      "0.882001322964492\n",
      "Fold:  5\n",
      "0.8826309227676468\n",
      "Fold:  6\n",
      "0.8793455362360649\n"
     ]
    }
   ],
   "source": [
    "# Set up level 1 models.\n",
    "RANDOM_SEED = 16\n",
    "lgbm = LGBMClassifier(application='binary',\n",
    "                      boosting='gbdt',\n",
    "                      learning_rate= 0.01,\n",
    "                      num_leaves=73,\n",
    "                      tree_learner='serial',\n",
    "                      num_threads=0,                      \n",
    "                      max_depth=23,\n",
    "                      min_data_in_leaf=5,\n",
    "                      min_sum_hessian_in_leaf=35.74237455449936,\n",
    "                      bagging_fraction=0.9476322568516703,\n",
    "                      bagging_freq=0,\n",
    "                      feature_fraction=1.0,\n",
    "                      lambda_l1=2.9721007219556626,\n",
    "                      lambda_l2=2.1415434246484737,\n",
    "                      boost_from_average=True,                      \n",
    "                      metric='auc'\n",
    "                     )\n",
    "nb = GaussianNB()\n",
    "\n",
    "# set up the meta classifier (level 2 model)\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n",
    "sclf = StackingCVClassifier(classifiers=[nb, lgbm], \n",
    "                            use_probas=True,\n",
    "                            use_features_in_secondary=True,\n",
    "                            meta_classifier=lr,\n",
    "                            cv=6)\n",
    "\n",
    "# Set up K-Fold cross validation and predictions\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 6\n",
    "folds = KFold(n_splits=num_folds, random_state=16)\n",
    "test_result = np.zeros(len(y_test))\n",
    "auc_score = 0\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n",
    "    print(\"Fold: \", fold_ + 1)\n",
    "    \n",
    "    X_train, Y_train = x_train.iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    X_valid, Y_valid = x_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    sclf.fit(X_train.values, Y_train['target'].values)\n",
    "    \n",
    "    Y_pred = sclf.predict_proba(X_valid)\n",
    "    auc = roc_auc_score(Y_valid, Y_pred[:, 1])\n",
    "    print(auc)\n",
    "    auc_score += auc\n",
    "\n",
    "    preds = sclf.predict_proba(x_test)\n",
    "    test_result += preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.8819540270768541\n"
     ]
    }
   ],
   "source": [
    "# print the average AUC across the folds and compute the final results on the test data\n",
    "auc_score = auc_score / folds.n_splits\n",
    "print(\"AUC score: \", auc_score)\n",
    "test_result = test_result / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.88264 \n"
     ]
    }
   ],
   "source": [
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(y_test, test_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('stacking_result.txt', test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
